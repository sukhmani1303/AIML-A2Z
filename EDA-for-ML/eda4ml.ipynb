{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLhkEpNSiLHOrueDz3VxEN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sukhmani1303/AIML-A2Z/blob/main/EDA-for-ML/eda4ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# **Introduction**\n",
        "---\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1FXKJxPDDHRL7aKUuZ-htp6IogPloVTst)\n",
        "\n",
        "---\n",
        "<br>\n",
        "\n",
        "## **What is AI ?** \n",
        "\n",
        "* ##### A program that can sense, adapt, read & act on its own. In short, anything that has an intelligence of its own.\n",
        "---\n",
        "<br>\n",
        "\n",
        "## **What is ML ?** \n",
        "* ##### Its a subset of AI which focusses on various Algorithms which help in machine's learning as more data gets fed/exposed to it.\n",
        "---\n",
        "<br>\n",
        "\n",
        "## **What is Deep Learning ?** \n",
        "* ##### Its a subset of ML where \"*Multi-Layered Neural Networks*\" are used to learn from huge amounts of data.\n",
        "---\n",
        "<br>\n",
        "\n",
        "## **Features Vs. Target** \n",
        "* ##### Features are the columns from where the data is studied for prediction.\n",
        "* ##### Target, also known as \"*label*\" is/are the column(s) to be predicted.\n",
        "---\n",
        "<br>\n",
        "\n",
        "## **Supervised Vs. Unsupervised Learning** \n",
        "* ##### Supervised Learning technique make use of \"*labelled*\" data for mainly **predictions using regressions or classification** algorithms. Example: Fraud Detection.\n",
        "* ##### Unsupervised Learning teachnique makes use \"*unlabelled*\" data for mainly **finding patterns or understanding the structure of data**. Example: Customer Segmentation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m2xYkC4yenn1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Retrieving Information**\n",
        "\n"
      ],
      "metadata": {
        "id": "dsqYFoDdmRPC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **From a CSV File**"
      ],
      "metadata": {
        "id": "XTzd4A1Smo4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using pandas library of python we can read csv data into a Dataframe\n",
        "import pandas as pd\n",
        "\n",
        "filepath = \"path/of/the/file.csv\"\n",
        "\n",
        "# importing the data using read_csv() function\n",
        "\n",
        "df_main = pd.read_csv(filepath)\n",
        "\n",
        "# We can pass different attributes into read_csv() function :\n",
        "\n",
        "sep = \"\\t\" # This sets the separation by a tab rather than \",\" (for .tsv files)\n",
        "header = None # This excludes the first row from our data from being exported\n",
        "names = ['column1', 'column2', 'column3'] # This specifies the only columns to be used\n",
        "na_values = [\"NA\",\"NAN\", 99] # to set custom Null values to specified values\n",
        "\n",
        "# to save the dataframe as csv\n",
        "df_main.to_csv(\"new/path/of/file.csv\" ,index = False)"
      ],
      "metadata": {
        "id": "f4bPdxF2mzHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **From a JSON File**"
      ],
      "metadata": {
        "id": "wvY5u6ZnpVsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "filepath = \"path/of/the/file.json\"\n",
        "\n",
        "df_main = pd.read_json(filepath)\n",
        "\n",
        "df_main.to_json(\"new/path/of/file.json\")"
      ],
      "metadata": {
        "id": "dZUO-A2GpbpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**"
      ],
      "metadata": {
        "id": "K_PWksmLqqeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Too much Data** - This becomes a data engineering problem as it first \n",
        "need to be organised & distributed before using it for ML\n",
        "\n",
        "* **Lack of Data** - ML algorithms need data to learn & this might lead to underfitting.\n",
        "\n",
        "* **Bad Data** - Garbage in - Garbage out\n",
        "\n",
        "* **Messy Data** \n",
        "\n",
        "  1.   Duplicate or unnecessary data\n",
        "  2.   Inconsistent text & typos\n",
        "  3.   Missing Data\n",
        "  4.   Outliers\n",
        "  5.   Data Sourcing issues\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1HiO2P3Cqwmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Missing Data**\n",
        "\n",
        "  1.   *Remove* the data ( rows or columns -> depends in nature & amount of data missing )\n",
        "  2.   *Impute* the data -> replace with standard data (mean, mode, median or any complex value)\n",
        "  3.   *Mask* the data -> using the missing info as important info for algorithm (using as a separate category)\n",
        "\n"
      ],
      "metadata": {
        "id": "J_7ZOoxJiNdr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Otliners**\n",
        "* ###### The Observation which is distinct from most observation. These are just observations which does not accurately represent the phenomenon we are trying to explain through model.\n",
        "\n",
        "* ###### Not removing the outliners can have a significant impact, but some outliners are informative\n",
        "\n",
        "## **How to find outliners ?**\n",
        "\n",
        "* ### **Plots**\n",
        "  1.   Histogram\n",
        "  2.   Density\n",
        "  3.   Box\n",
        "\n",
        "* ### **Statistics**\n",
        "  1.   Interquartile Range\n",
        "  2.   Standard Deviation\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "j4KIzh2ZoTwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting a histogram using seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "sns.distplot(data, bins = 20)"
      ],
      "metadata": {
        "id": "zXMha3R2rsZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plotting a box plot using seaborn\n",
        "import seaborn as sns\n",
        "\n",
        "sns.boxplot(data)"
      ],
      "metadata": {
        "id": "8_jG1Tq6sAfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mathematical methods for finding Outliners\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#getting the 25th, 50th & 75th quartile ranges :\n",
        "q25, q50, q75 = np.percentile(data, [25,50,75])\n",
        "\n",
        "#getting the interquartile range\n",
        "iqr = q75 - q50\n",
        "\n",
        "#calculating the min & max limits to be considered as an outliner\n",
        "min = q25 - 1.5*(1qr)\n",
        "max = q75 + 1.5*(1qr)\n",
        "\n",
        "print(min, q25, q50, q75, max)\n",
        "\n",
        "# identify the Outliners :\n",
        "outliners = [x for x in data['columns'] if x>max]\n"
      ],
      "metadata": {
        "id": "h9szQMQ8sSAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Residuals**\n",
        "###### (*represent model failure*)\n",
        "###### differences between actual & predicted values of the ourcome variable.\n",
        "\n",
        "*   **Standardized** - residual divided by standard error\n",
        "*   **Deleted** - delete the residual observation & retrain\n",
        "*   **Studentized** - deleted residuals are standardized\n",
        "\n"
      ],
      "metadata": {
        "id": "afPLSMlGvjVj"
      }
    }
  ]
}